- name: set spark fact
  set_fact: spark_installed=True

- name: set spark installation path fact
  set_fact: spark_installation_dir=spark-{{ spark.version }}-bin-hadoop{{ spark.hadoop_version }}

- name: set spark archive fact
  set_fact: spark_archive=spark-{{ spark.version }}-bin-hadoop{{ spark.hadoop_version }}.tgz

- name: set spark download location fact
  set_fact: spark_download={{ spark.download_location }}/spark-{{ spark.version }}/{{ spark_archive }}

- name: define number of spark workers
  set_fact: number_of_workers="{{ groups['nodes'] | length | int }}"

- name: create install directory
  file:
    path: "{{ install_dir }}/{{ spark_installation_dir }}"
    state: directory

- debug:
     msg: "Downloading Spark from: {{ spark_download }}"

- name: download spark
  get_url: url="{{ spark_download }}" dest="{{ install_temp_dir }}/{{ spark_archive }}"

- name: unarchive to the install directory
  shell: "tar -xvf {{ install_temp_dir }}/{{ spark_archive }} --strip 1 --directory {{ install_dir }}/{{ spark_installation_dir }}"

- name: create spark working directory
  file:
    path: "{{ spark.working_dir }}"
    state: directory

- name: set spark-env.sh
  template: src="spark-env-sh.j2" dest="{{ install_dir }}/{{ spark_installation_dir }}/conf/spark-env.sh"

- name: set spark-defaults.conf
  template: src="spark-defaults-conf.j2" dest="{{ install_dir}}/{{ spark_installation_dir }}/conf/spark-defaults.conf"

- name: set slaves
  template: src="slaves.j2" dest="{{ install_dir}}/{{ spark_installation_dir }}/conf/slaves"

- name: stop spark
  shell: "sbin/stop-all.sh"
  args:
      chdir: "{{ install_dir}}/{{ spark_installation_dir }}"
  ignore_errors: yes
  when: inventory_hostname in groups['master']

- name: stop history_server
  shell: "sbin/stop-history-server.sh"
  args:
      chdir: "{{ install_dir}}/{{ spark_installation_dir }}"
  ignore_errors: yes
  when: inventory_hostname in groups['master']

- name: start spark
  shell: "sbin/start-all.sh"
  args:
      chdir: "{{ install_dir}}/{{ spark_installation_dir }}"
  ignore_errors: yes
  when: inventory_hostname in groups['master']

- name: start history_server
  shell: "sbin/start-history-server.sh"
  args:
      chdir: "{{ install_dir}}/{{ spark_installation_dir }}"
  ignore_errors: yes
  when: inventory_hostname in groups['master']

- name: add spark profile to startup
  template:
    src: spark-profile.sh.j2
    dest: /etc/profile.d/spark-profile.sh
    mode: 0644

- name: Spark Smoke Test
  shell: "/mnt/data0/spark/spark-3.1.2-bin-hadoop3.2/bin/spark-submit --master spark://172.31.26.39:7077 --deploy-mode cluster --class org.apache.spark.examples.SparkPi /mnt/data0/spark/spark-3.1.2-bin-hadoop3.2/examples/jars/spark-examples_2.12-3.1.2.jar"
  when: inventory_hostname in groups['master']
    #- name: spark smoke test
  #  sudo: yes
  #  connection: ssh
  #tasks:
  # - name: Submit test application
  #   shell: "{{ SPARK_HOME }}/bin/spark-submit --class org.apache.spark.examples.SparkPi /examples/jars/spark-examples_2.12-3.1.2.jar"
  #   register: output
  # - name: show the value of output
  #   debug: var=output
  #when: inventory_hostname in groups['master']
